{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7b4845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"AWS_PROFILE\"]=\"isengard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbc10141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import asyncio\n",
    "from typing import Optional, List, Dict, Any\n",
    "import json\n",
    "import sys\n",
    "\n",
    "\n",
    "from agent_squad.orchestrator import AgentSquad, AgentSquadConfig\n",
    "from agent_squad.agents import (BedrockLLMAgent,\n",
    "                        BedrockLLMAgentOptions,\n",
    "                        AgentResponse,\n",
    "                        AnthropicAgent, AnthropicAgentOptions,\n",
    "                        AgentCallbacks)\n",
    "from agent_squad.types import ConversationMessage, ParticipantRole\n",
    "from agent_squad.classifiers import BedrockClassifier, BedrockClassifierOptions\n",
    "\n",
    "\n",
    "class LLMAgentCallbacks(AgentCallbacks):\n",
    "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
    "        # handle response streaming here\n",
    "        print(\"token printing\\n\")\n",
    "        print(token, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2050b4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the orchestrator with some options\n",
    "orchestrator = AgentSquad(\n",
    "    options=AgentSquadConfig(\n",
    "        LOG_AGENT_CHAT=True,\n",
    "        LOG_CLASSIFIER_CHAT=True,\n",
    "        LOG_CLASSIFIER_RAW_OUTPUT=True,\n",
    "        LOG_CLASSIFIER_OUTPUT=True,\n",
    "        LOG_EXECUTION_TIMES=True,\n",
    "        MAX_RETRIES=3,\n",
    "        USE_DEFAULT_AGENT_IF_NONE_IDENTIFIED=True,\n",
    "        MAX_MESSAGE_PAIRS_PER_AGENT=10,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add some agents\n",
    "tech_agent = BedrockLLMAgent(\n",
    "    BedrockLLMAgentOptions(\n",
    "        name=\"Tech Agent\",\n",
    "        streaming=True,\n",
    "        description=\"Specializes in technology areas including software development, hardware, AI, \\\n",
    "        cybersecurity, blockchain, cloud computing, emerging tech innovations, and pricing/costs \\\n",
    "        related to technology products and services.\",\n",
    "        model_id=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "        callbacks=LLMAgentCallbacks(),\n",
    "        inference_config={\"maxTokens\": 2500, \"temperature\": 1},\n",
    "        reasoning_config={\"thinking\": {\"type\": \"enabled\", \"budget_tokens\": 2000}},\n",
    "    )\n",
    ")\n",
    "orchestrator.add_agent(tech_agent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab9a1761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "\n",
    "async def handle_request(_orchestrator: AgentSquad, _user_input: str, _user_id: str, _session_id: str):\n",
    "    response: AgentResponse = await _orchestrator.route_request(_user_input, _user_id, _session_id)\n",
    "\n",
    "    # Print metadata\n",
    "    print(\"\\nMetadata:\")\n",
    "    print(f\"Selected Agent: {response.metadata.agent_name}\")\n",
    "    if isinstance(response, AgentResponse) and response.streaming is False:\n",
    "        # Handle regular response\n",
    "        if isinstance(response.output, str):\n",
    "            print(response.output)\n",
    "        elif isinstance(response.output, ConversationMessage):\n",
    "            print(response.output.content[0].get(\"text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2daeb0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:agent_squad.utils.logger:\n",
      "** CLASSIFIED INTENT **\n",
      "INFO:agent_squad.utils.logger:=======================\n",
      "INFO:agent_squad.utils.logger:> Text: what is blockchain\n",
      "INFO:agent_squad.utils.logger:> Selected Agent: Tech Agent\n",
      "INFO:agent_squad.utils.logger:> Confidence: 0.95\n",
      "INFO:agent_squad.utils.logger:\n",
      "INFO:agent_squad.utils.logger:\n",
      "** AGENT TECH-AGENT CHAT HISTORY **\n",
      "INFO:agent_squad.utils.logger:===================================\n",
      "INFO:agent_squad.utils.logger:> - None -\n",
      "INFO:agent_squad.utils.logger:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token printing\n",
      "\n",
      "#"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:agent_squad.utils.logger:Error getting stream from Bedrock model: object NoneType can't be used in 'await' expression\n",
      "ERROR:agent_squad.utils.logger:Error during agent processing: object NoneType can't be used in 'await' expression\n",
      "INFO:agent_squad.utils.logger:\n",
      "** EXECUTION TIMES **\n",
      "INFO:agent_squad.utils.logger:=====================\n",
      "INFO:agent_squad.utils.logger:> Classifying user intent: 2.3845510482788086s\n",
      "INFO:agent_squad.utils.logger:> Agent Tech Agent | Processing request: 5.412101745605469e-05s\n",
      "INFO:agent_squad.utils.logger:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata:\n",
      "Selected Agent: No Agent\n",
      "object NoneType can't be used in 'await' expression\n",
      "\n",
      "Response:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "USER_ID = \"user123\"\n",
    "SESSION_ID = str(uuid.uuid4())\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "user_input = \"what is blockchain\"\n",
    "\n",
    "\n",
    "# Run the async function\n",
    "loop = asyncio.get_event_loop()\n",
    "response = loop.run_until_complete(handle_request(orchestrator, user_input, USER_ID, SESSION_ID))\n",
    "print(f\"\\nResponse:\\n{response}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
